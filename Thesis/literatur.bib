@article{dartmouth,
title={A Proposal for the Dartmouth Summer Research Project on Artifical Intelligence},
author={J. McCarthy, M. L. Minsky, N. Rochester, C.E. Shannon},
year={1955}
}

@misc{buffet2020reinforcement,
      title={Reinforcement Learning}, 
      author={Olivier Buffet and Olivier Pietquin and Paul Weng},
      year={2020},
      eprint={2005.14419},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{ Deepl,
author = "{Wikipedia contributors}",
title = "Deep Learning",
url = "https://en.wikipedia.org/w/index.php?title=Deep_learning&oldid=1188873173",
note = "[Online; accessed 08-Dec-2023]"
}

@book{ivakhnenko1967cybernetics,
  title={Cybernetics and Forecasting Techniques},
  author={Ivakhnenko, A.G. and Lapa, V.G.},
  isbn={9780444000200},
  lccn={67027815},
  series={Modern analytic and computational methods in science and mathematics},
  url={https://books.google.de/books?id=rGFgAAAAMAAJ},
  year={1967},
  publisher={American Elsevier Publishing Company}
}

@inproceedings{NIPS2012_c399862d,
 author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {F. Pereira and C.J. Burges and L. Bottou and K.Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {ImageNet Classification with Deep Convolutional Neural Networks},
 url = {https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf},
 volume = {25},
 year = {2012}
}

@misc{GRU,
      title={Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation}, 
      author={Kyunghyun Cho and Bart van Merrienboer and Caglar Gulcehre and Dzmitry Bahdanau and Fethi Bougares and Holger Schwenk and Yoshua Bengio},
      year={2014},
      eprint={1406.1078},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{LLM,
      title={Language Models are Few-Shot Learners}, 
      author={Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
      year={2020},
      eprint={2005.14165},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{LSTM,
author = {Hochreiter, Sepp and Schmidhuber, J\"{u}rgen},
title = {Long Short-Term Memory},
year = {1997},
issue_date = {November 15, 1997},
publisher = {MIT Press},
address = {Cambridge, MA, USA},
volume = {9},
number = {8},
issn = {0899-7667},
url = {https://doi.org/10.1162/neco.1997.9.8.1735},
doi = {10.1162/neco.1997.9.8.1735},
journal = {Neural Comput.},
month = {nov},
pages = {1735–1780},
numpages = {46}
}

@misc{vaswani2023attention,
      title={Attention Is All You Need}, 
      author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
      year={2023},
      eprint={1706.03762},
      archivePrefix={arXiv},
      primaryClass={cs.CL}@article{10.1162/neco.1997.9.8.1735,
author = {Hochreiter, Sepp and Schmidhuber, J\"{u}rgen},
title = {Long Short-Term Memory},
year = {1997},
issue_date = {November 15, 1997},
publisher = {MIT Press},
address = {Cambridge, MA, USA},
volume = {9},
number = {8},
issn = {0899-7667},
url = {https://doi.org/10.1162/neco.1997.9.8.1735},
doi = {10.1162/neco.1997.9.8.1735},
abstract = {Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.},
journal = {Neural Comput.},
month = {nov},
pages = {1735–1780},
numpages = {46}
}
}


@article{cortes1995support,
  title={Support-vector networks},
  author={Cortes, Corinna and Vapnik, Vladimir},
  journal={Machine learning},
  volume={20},
  number={3},
  pages={273--297},
  year={1995},
  publisher={Springer}
}


@article{LeCun1989BackpropagationAT,
  title={Backpropagation Applied to Handwritten Zip Code Recognition},
  author={Yann LeCun and Bernhard E. Boser and John S. Denker and Donnie Henderson and Richard E. Howard and Wayne E. Hubbard and Lawrence D. Jackel},
  journal={Neural Computation},
  year={1989},
  volume={1},
  pages={541-551},
  url={https://api.semanticscholar.org/CorpusID:41312633}
}


@article{SML,
title={Supervised Machine Learning: A Survey},
author={Mohammed ; Khalid ; Ahmed},
year={2021},
pages={2--3},
publisher={IEEE}
}

@article{svm,
title={Support-vector networks},
author={Cortes, Corinna and Vapnik, Vladimir},
journal={Machine learning},
volume={20},
number={3},
pages={273--297},
year={1995},
publisher={Springer}
}

@Inbook{Jin2010,
author="Jin, Xin
and Han, Jiawei",
editor="Sammut, Claude
and Webb, Geoffrey I.",
title="K-Means Clustering",
bookTitle="Encyclopedia of Machine Learning",
year="2010",
publisher="Springer US",
address="Boston, MA",
pages="563--564",
isbn="978-0-387-30164-8",
doi="10.1007/978-0-387-30164-8_425",
url="https://doi.org/10.1007/978-0-387-30164-8_425"
}

@article{DR,
title = {A Review of Dimensionality Reduction Techniques for Efficient Computation},
journal = {Procedia Computer Science},
volume = {165},
pages = {104-111},
year = {2019},
note = {2nd International Conference on Recent Trends in Advanced Computing ICRTAC -DISRUP - TIV INNOVATION , 2019 November 11-12, 2019},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2020.01.079},
url = {https://www.sciencedirect.com/science/article/pii/S1877050920300879},
author = {S. Velliangiri and S. Alagumuthukrishnan and S Iwin {Thankumar joseph}},
}

@Inbook{Cios2007,
author="Cios, Krzysztof J.
and Swiniarski, Roman W.
and Pedrycz, Witold
and Kurgan, Lukasz A.",
title="Unsupervised Learning: Association Rules",
bookTitle="Data Mining: A Knowledge Discovery Approach",
year="2007",
publisher="Springer US",
address="Boston, MA",
pages="289--306",
isbn="978-0-387-36795-8",
doi="10.1007/978-0-387-36795-8_10",
url="https://doi.org/10.1007/978-0-387-36795-8_10"
}

@misc{sup_vs_unsup,
author = {Morimoto, Juliano and Ponton, Fleur},
year = {2021},
month = {05},
pages = {},
title = {Virtual reality in biology: could we become virtual naturalists?},
volume = {14},
journal = {Evolution: Education and Outreach},
note = {\url{https://www.researchgate.net/publication/351953193_Virtual_reality_in_biology_could_we_become_virtual_naturalists}},
}

@Misc{WWWBibTex,
  key =		 {BibTex},
  title =	 {Help on BibTex},
  howpublished = {\url{http://www.nwalsh.com/tex/texhelp/BibTeX.html}},
  year =	 {2003}
}

@Misc{WWWPospiech,
  key =		 {Pospiech},
  title =	 {Linkssammlung zu \LaTeX\ von Matthias Pospiech},
  howpublished = {\url{http://maitre.physik.uni-kl.de/~pospiech/}},
  year =	 {2003}
}

@Misc{WWWMikTex,
  key =		 {MikTex},
  title =	 {MikTex Project Page},
  howpublished = {\url{http://www.miktex.org}},
  year =	 {2003}
}

@Misc{WWWDante,
  key =		 {Dante},
  title =	 {DANTE, Deutschsprachige Anwendervereinigung TeX
                  e.V.},
  howpublished = {\url{http://www.dante.de}},
  year =	 {2003}
}

@Book{Lamport95,
  author =	 {Leslie Lamport},
  title =	 {Das LaTeX-Handbuch},
  publisher =	 {Addison-Wesley},
  year =	 {1995}
}

@Book{Goossens96,
  author =	 {Michel Goossens and Frank Mittelbach and Alexander
                  Samarin},
  title =	 {Der LaTeX-Begleiter},
  publisher =	 {Addison-Wesley},
  year =	 {1996}
}

%%%%%%%%%%%%%%%%%%%% Beispiele

%% Ein Beispiel (für einen Artikel in einer Zeitschrift):
@Article{Albiez03,
author = {J. Albiez and T. Luksch and K. Berns and R. Dillmann},
title = {An Activation-Based Behavior Control Architecture for Walking Machines},
journal = {The International Journal on Robotics Research, Sage Publications},
year = {2003},
volume = {22},
pages = {203--211}
}

%% Noch ein Beispiel (für ein Paper):
@inproceedings{Berns06,
  author = {K. Berns and J. Hirth},
  title = {Control of facial expressions of the humanoid robot head ROMAN},
  booktitle = {IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  year = {2006},
  pages = {3119--3124},
  address = {Beijing, China},
  month = {October 9--15},
}

%% Noch ein Beispiel (ein Kapitel in einem Buch, in dem verschiedene Autoren verschiedene Kapitel geschrieben haben):
@InCollection{Ilg99,
  author = {W. Ilg and T. Muehlfriedel and K. Berns and  R. Dillmann},
  title = {Hybrid learning concepts for a biological inspired control of periodic movements  for  walking machines},
  booktitle = {Soft Computing in Mechatronics},
  year = {1999},
  pages = {19--38},
  publisher = {Springer Verlag},
  editor = {K.Hirota and T. Fukuda},
  month = {August},
}

%% Noch ein Beispiel (die Proceedings einer Konferenz):
@Proceedings{Berns07,
  title = {Autonome Mobile Systeme 2007},
  publisher = {Springer},
  year = {2007},
  editor = {K. Berns and T. Luksch},
  series = {Informatik aktuell},
  address = {Kaiserslautern},
  month = {October 18--19},
}

%% Noch ein Beispiel (ein Buch):
@Book{Arkin98,
  author =	 {R. Arkin},
  title =	 {Behavior-Based Robotics},
  year =	 {1998},
  publisher =	 {MIT Press},
  address = {Cambridge, USA}
}

%% Noch ein Beispiel (ein Kapitel in einem Buch - das Kapitel ist von dem Buch-Autor):
@InBook{Mendel70,
  author = {J.M. Mendel and R.W. McLaren},
  title = {Adaptive Learning and Pattern Recognition Systems: Theory and Applications},
  chapter = {Reinforcement learning control and pattern recognition systems},
  publisher = {Academic Press, New York},
  year = {1970},
  pages = {287--318}
}

%% Noch ein Beispiel (eine Doktorarbeit):
@PhdThesis{Breazeal00,
  author = {C.L. Breazeal},
  title = {Sociable Machines: Expressive Social Exchange Between Humans and Robots},
  school = {Massachusetts Institute Of Technology},
  year = {2000},
  month = {May}
}

%% Noch ein Beispiel (eine Diplomarbeit; Projektarbeiten werden genauso eingeragen nur mit 'Project' statt 'Diploma'):
@MastersThesis{Luksch02,
  author = {T. Luksch},
  title = {Verhaltensbasierte freie Gangart f\"{u}r eine vierbeinige Laufmaschine},
  school = {Universit\"{a}t Karlsruhe, Forschungszentrum Informatik (FZI) Karlsruhe},
  year = {2002},
  type = {Diploma Thesis, unpublished},
  month = {August}
}

%% Noch ein Beispiel (ein technischer Bericht):
@TechReport{Schaefer03,
  author = {J. Brandt and H. Sch\"{a}fer},
  title = {SmoothBrake --- A Prototyping Case Study},
  institution = {Robotics Research Lab - Technische universit\"{a}t Kaiserslautern},
  year = {2003},
  type = {Technical Report, unpublished},
}
